{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OIGyknEK9xP",
        "outputId": "ac57968b-0c7c-468a-8eec-f33d476bbbf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.13-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting cohere\n",
            "  Downloading cohere-5.8.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.41.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.30 (from langchain)\n",
            "  Downloading langchain_core-0.2.32-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.99-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting boto3<2.0.0,>=1.34.0 (from cohere)\n",
            "  Downloading boto3-1.34.161-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting httpx>=0.21.2 (from cohere)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting httpx-sse==0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.20.1)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.19.1)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20240712-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.112.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.5.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting botocore<1.35.0,>=1.34.161 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading botocore-1.34.161-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx>=0.21.2->cohere)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.21.2->cohere)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.30->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading langchain-0.2.13-py3-none-any.whl (997 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cohere-5.8.0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.8/207.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading gradio-4.41.0-py3-none-any.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading boto3-1.34.161-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.32-py3-none-any.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.8/389.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.99-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.5.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading types_requests-2.32.0.20240712-py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.112.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading botocore-1.34.161-py3-none-any.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: pydub, websockets, types-requests, tomlkit, tenacity, semantic-version, ruff, python-multipart, python-dotenv, parameterized, orjson, jsonpointer, jmespath, httpx-sse, h11, ffmpy, fastavro, aiofiles, uvicorn, starlette, jsonpatch, httpcore, botocore, s3transfer, langsmith, httpx, fastapi, langchain-core, gradio-client, boto3, langchain-text-splitters, gradio, cohere, langchain\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.0\n",
            "    Uninstalling tomlkit-0.13.0:\n",
            "      Successfully uninstalled tomlkit-0.13.0\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed aiofiles-23.2.1 boto3-1.34.161 botocore-1.34.161 cohere-5.8.0 fastapi-0.112.0 fastavro-1.9.5 ffmpy-0.4.0 gradio-4.41.0 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 httpx-sse-0.4.0 jmespath-1.0.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.13 langchain-core-0.2.32 langchain-text-splitters-0.2.2 langsmith-0.1.99 orjson-3.10.7 parameterized-0.9.0 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.5.7 s3transfer-0.10.2 semantic-version-2.10.0 starlette-0.37.2 tenacity-8.5.0 tomlkit-0.12.0 types-requests-2.32.0.20240712 uvicorn-0.30.6 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain cohere python-dotenv gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl9sQth9TUGa",
        "outputId": "4974a1c3-61d6-49c4-a99f-421da40dbd4f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.13 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.13)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.32)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.99)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (2.20.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.2.12-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.12 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "from dotenv import load_dotenv\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import Tool\n",
        "from langchain.agents import AgentType\n",
        "from langchain.llms import Cohere\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "8Q7avXt1TVBw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['COHERE_API_KEY'] = \"nhYrFwn0xNFthWrVy6YwUEGES2hMwsc0hRDjTnlh\"\n",
        "os.environ['TAVILY_API_KEY'] = \"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\""
      ],
      "metadata": {
        "id": "Kipkut6VTebo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize API wrappers\n",
        "search = TavilySearchResults()"
      ],
      "metadata": {
        "id": "gJ3u68hCTjRE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about current events\"\n",
        "    )]"
      ],
      "metadata": {
        "id": "2dGmG4pgTkdz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Cohere language model\n",
        "llm = Cohere(temperature=0.4, model=\"command-r-plus\")\n",
        "#chat = ChatCohere(model=\"command-r-plus\", temperature=0.3)"
      ],
      "metadata": {
        "id": "71PAmEBvTymg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up memory which allows for storing messages and then extracts the messages in a variable.\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
      ],
      "metadata": {
        "id": "lzo5RypBT1wo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the agent\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oh_HbcaT4Ib",
        "outputId": "35986f69-8fcc-480a-c57d-182ce0224faf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(message, history):\n",
        "    # Convert history to the format expected by the agent\n",
        "    chat_history = []\n",
        "    for human, ai in history:\n",
        "        chat_history.append(f\"Human: {human}\")\n",
        "        chat_history.append(f\"AI: {ai}\")\n",
        "\n",
        "    # Run the agent\n",
        "    response = agent.run(input=message, chat_history=chat_history)\n",
        "\n",
        "    # Return the response\n",
        "    return response"
      ],
      "metadata": {
        "id": "u2L49FerT9T6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface = gr.ChatInterface(\n",
        "    chatbot,\n",
        "    chatbot=gr.Chatbot(height=300),\n",
        "    textbox=gr.Textbox(placeholder=\"Ask me anything...\", container=False, scale=7),\n",
        "    title=\"AI Agent\",\n",
        "    description=\"Ask me anything, and I'll use my tools to find the answer!\",\n",
        "    theme=\"soft\",\n",
        "    examples=[\n",
        "        \"What is the difference between generative and discriminative models?\",\n",
        "        \"Describe the architecture of a Generative Adversarial Network and how the generator and discriminator interact during training.\",\n",
        "        \"Explain the concept of a Variational Autoencoder (VAE) and how it incorporates latent variables into its architecture.\",\n",
        "        \"How do conditional generative models differ from unconditional ones? Provide an example scenario where a conditional approach is beneficial.\",\n",
        "        \"What is mode collapse in the context of GANs, and what strategies can be employed to address it during training?\",\n",
        "        \"How does overfitting manifest in generative models, and what techniques can be used to prevent it during training?\",\n",
        "        \"What is gradient clipping, and how does it help in stabilizing the training process of generative models?\",\n",
        "        \"what is langchain?\",\n",
        "        \"what is rnn? explain the architecture of rnn?\",\n",
        "        \"Discuss strategies for training generative models when the available dataset is limited?\",\n",
        "        \"Explain how curriculum learning can be applied in the training of generative models. What advantages does it offer?\",\n",
        "        \"Describe the concept of learning rate scheduling and its role in optimizing the training process of generative models over time?\"\n",
        "    ],\n",
        "    cache_examples=True,\n",
        "    retry_btn=None,\n",
        "    undo_btn=\"Delete Previous\",\n",
        "    clear_btn=\"Clear\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHU3tsUtT-Ze",
        "outputId": "76deee6e-d98a-4ba9-fae9-a7bd0e1ab882"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caching examples at: '/content/gradio_cached_examples/15'\n",
            "Caching example 1/12\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Generative models and discriminative models are two different types of algorithms used in machine learning. \n",
            "\n",
            "Generative models aim to generate new data that follows the same statistical distribution as the training data. These models learn the underlying probability distribution of the data and can be used to generate new, synthetic data samples. Examples of generative models include Gaussian mixture models and generative adversarial networks (GANs).\n",
            "\n",
            "On the other hand, discriminative models focus on learning a function that can discriminate between different classes or categories in the data. These models learn a mapping from input variables to output variables and are often used for classification or prediction tasks. Examples of discriminative models include logistic regression, decision trees, and neural networks.\n",
            "\n",
            "In summary, the key difference lies in their objectives: generative models aim to generate new data, while discriminative models aim to discriminate between different classes or categories in the data.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Caching example 2/12\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Search\n",
            "Action Input: Architecture of a Generative Adversarial Network\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[{'url': 'https://www.geeksforgeeks.org/generative-adversarial-network-gan/', 'content': 'Data Structures and Algorithms\\nML & Data Science\\nWeb Development\\nLanguages\\nInterview Corner\\nCS Subjects\\nJobs\\nPractice\\nContests\\nIntroduction to Deep Learning\\nBasic Neural Network\\nActivation Functions\\nArtificial Neural Network\\nClassification\\nRegression\\nHyperparameter tuning\\nIntroduction to Convolution Neural Network\\nRecurrent Neural Network\\nGated Recurrent Unit Networks\\nGenerative Learning\\nGenerative adversarial networks\\nReinforcement Learning\\nQ-Learning in Python\\nDeep Q Learning\\nIntroduction to Deep Learning\\nBasic Neural Network\\nActivation Functions\\nArtificial Neural Network\\nClassification\\nRegression\\nHyperparameter tuning\\nIntroduction to Convolution Neural Network\\nRecurrent Neural Network\\nGated Recurrent Unit Networks\\nGenerative Learning\\nGenerative adversarial networks\\nReinforcement Learning\\nQ-Learning in Python\\nDeep Q Learning\\nGenerative Adversarial Network (GAN)\\nGenerative Adversarial Networks, or GANs, represent a cutting-edge approach to generative modeling within deep learning, often leveraging architectures like convolutional neural networks. Generative Adversarial Networks (GANs) can be broken down into three parts:\\nArchitecture of GAN\\nA Generative Adversarial Network (GAN) is composed of two primary parts, which are the Generator and the Discriminator.\\n An image (img) is the discriminator’s input, and its validity—the probability that the input image is real as opposed to artificial—is its output.\\n Notable applications include image-to-image translation tasks and the creation of photorealistic images indistinguishable from real photos, demonstrating the transformative potential of GANs in the realm of generative modeling.\\n The discriminator grows increasingly discriminating as a result of the generator and discriminator’s interaction, which helps the GAN produce extremely realistic-looking synthetic data overall.\\n'}, {'url': 'https://cs.stanford.edu/~amishkin/assets/slides/gans.pdf', 'content': 'Generative adversarial networks. arxiv e-prints. arXiv preprint arXiv:1406.2661, 2014. Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative adversarial networks. arXiv preprint arXiv:1812.04948, 2018.'}, {'url': 'https://developers.google.com/machine-learning/gan/gan_structure', 'content': \"Overview of GAN Structure. A generative adversarial network (GAN) has two parts: The generator learns to generate plausible data. The generated instances become negative training examples for the discriminator. The discriminator learns to distinguish the generator's fake data from real data.\"}, {'url': 'https://towardsdatascience.com/a-comprehensive-guide-to-generative-adversarial-networks-gans-fcfe65d1cfe4', 'content': 'GAN is essentially a neural network architecture (more of a framework than an architecture), wherein a generative model is paired with a non-generative model; the generative model is penalized for a bad quality generation, whereas, the other model is penalized for a good quality generation by the generative model. So in a way, these models compete to achieve their individual goals. The ...'}, {'url': 'https://machinelearningmastery.com/tour-of-generative-adversarial-network-models/', 'content': 'Specifically, the goal is to add specific semantic meaning to the variables in the latent space.\\n… , when generating images from the MNIST dataset, it would be ideal if the model automatically chose to allocate a discrete random variable to represent the numerical identity of the digit (0-9), and chose to have two additional continuous variables that represent the digit’s angle and thickness of the digit’s stroke.\\n We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake.\\n— Generative Adversarial Networks, 2014.\\n The critic is updated to output a real-value (linear activation) instead of a binary prediction with a sigmoid activation, and the critic and generator models are both trained using “Wasserstein loss,” which is the average of the product of real and predicted values from the critic, designed to provide linear gradients that are useful for updating the model.\\n The auxiliary classifier generative adversarial network, or AC-GAN, is an extension to the GAN that both changes the generator to be class conditional as with the cGAN, and adds an additional or auxiliary model to the discriminator that is trained to reconstruct the class label.\\n Foundation Papers\\nExtension Papers\\nAdvanced Papers\\nArticles\\nSummary\\nIn this post, you discovered the Generative Adversarial Network models that you need to know to establish a useful and productive foundation in the field\\nSpecifically, you learned:\\nDo you have any questions?\\n'}]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mAI: A Generative Adversarial Network (GAN) is composed of two main parts: the generator and the discriminator. The generator aims to create synthetic data that resembles the real data distribution, while the discriminator learns to distinguish between real data and the generator's synthetic data.\n",
            "\n",
            "The architecture of a GAN can be described as follows:\n",
            "1. The generator takes random noise as input and generates synthetic data samples.\n",
            "2. The discriminator takes the synthetic data from the generator and/or real data from the training dataset as input.\n",
            "3. The discriminator outputs a probability value, indicating the likelihood of the input data being real or synthetic.\n",
            "4. The discriminator's feedback is then used to update the generator, helping it to produce more realistic synthetic data.\n",
            "5. This process continues iteratively, with the generator and discriminator improving through their interaction.\n",
            "\n",
            "The generator and discriminator are often implemented as neural networks, with the generator typically being a deconvolutional network and the discriminator being a convolutional network. During training, the discriminator becomes increasingly discriminating, which, in turn, pushes the generator to produce more realistic synthetic data. This adversarial interaction is what gives GANs their name and allows them to generate high-quality synthetic data that can be used\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Caching example 3/12\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: A Variational Autoencoder (VAE) is a type of neural network architecture that combines autoencoding with variational Bayesian inference. It is designed to effectively learn compressed representations of input data, often in an unsupervised manner.\n",
            "\n",
            "At a high level, a VAE consists of an encoder and a decoder, similar to a traditional autoencoder. However, the key difference lies in the incorporation of latent variables and the probabilistic nature of the model.\n",
            "\n",
            "Here's a step-by-step explanation of the VAE architecture and how it incorporates latent variables:\n",
            "\n",
            "1. **Encoder**: The encoder, also known as the recognition model, takes the input data and maps it to a latent representation. In a VAE, the encoder typically outputs the parameters of a probability distribution, such as the mean and standard deviation of a Gaussian distribution. This distribution represents the approximate posterior distribution of the latent variables given the input data.\n",
            "\n",
            "2. **Latent Variables**: Latent variables are the compressed representation of the input data. In a VAE, the latent variables are random variables sampled from the probability distribution output by the encoder. This sampling process introduces stochasticity into the model, allowing it to capture the\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Caching example 4/12\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Conditional generative models incorporate additional information, often in the form of conditional variables or labels, during the generation process. This allows the model to generate outputs that are conditioned on specific inputs or constraints. On the other hand, unconditional generative models generate outputs without any specific conditions or constraints. They aim to capture the overall distribution of the training data.\n",
            "\n",
            "An example scenario where a conditional approach is beneficial is text generation. Let's say we want to generate descriptive sentences about different animals. An unconditional model might generate sentences like \"The elephant walks slowly\" or \"The bird flies high\". However, with a conditional model, we can provide additional information, such as the animal's name or specific attributes. For instance, if we input the condition \"animal: lion\", the model might generate sentences like \"The lion roars loudly, showcasing its majestic mane\" or \"The lion prowls gracefully through the savanna\". This conditional approach allows for more targeted and contextually relevant generation, which can be useful in various applications, including language generation, image synthesis, and controlled data generation.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Caching example 5/12\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Mode collapse in the context of Generative Adversarial Networks (GANs) refers to a situation where the generator network produces limited varieties of samples or loses the variation capability, resulting in a lack of diversity in the generated data. In other words, the generator gets stuck in a local minimum and keeps producing similar outputs, failing to explore the full range of possible data distributions.\n",
            "\n",
            "To address mode collapse during training, several strategies can be employed:\n",
            "\n",
            "- **Diversity Regularization**: This technique encourages the generator to produce diverse outputs by adding a penalty term to the loss function. The penalty discourages the generator from producing similar outputs and promotes exploration of different modes in the data distribution.\n",
            "\n",
            "- **Minibatch Discrimination**: This approach modifies the discriminator by adding a feature that captures the similarity between samples within a minibatch. This helps the discriminator to distinguish between real and fake data, as well as identify mode collapse in the generator's outputs.\n",
            "\n",
            "- **Use of Conditional GANs**: Conditional GANs, as discussed earlier, can be used to condition the generator on specific inputs or constraints, guiding the generation process and reducing the chances of mode collapse.\n",
            "\n",
            "- **Architect\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Caching example 6/12\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Overfitting in the context of generative models refers to the situation where the model learns the training data too well and ends up memorizing the training examples, resulting in poor generalization to new, unseen data. In other words, the model becomes too specialized to the training data and fails to capture the underlying patterns and distributions present in the broader dataset.\n",
            "\n",
            "To prevent overfitting during training, the following techniques can be employed:\n",
            "\n",
            "- **Early Stopping**: This technique involves monitoring the model's performance on a validation set during training and stopping the training process when the model starts to overfit. By stopping the training at an optimal point, the model can generalize better to new data.\n",
            "\n",
            "- **Regularization**: Regularization techniques, such as Dropout or weight decay, can be used to introduce additional constraints on the model's parameters. These techniques help to prevent the model from relying too heavily on specific features or patterns in the training data, encouraging it to learn more general representations.\n",
            "\n",
            "- **Data Augmentation**: Data augmentation techniques involve creating modified versions of the training data by applying random transformations, such as rotation, scaling, or flipping. By increasing the diversity of the training data, the\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Caching example 7/12\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Gradient clipping is a technique used in machine learning to stabilize the training process, particularly for generative models. It involves rescaling gradients during backpropagation to ensure they remain within a certain range. By \"clipping\" the gradients, we prevent them from growing too large, which can cause unstable behavior and even NaN (Not a Number) values during training.\n",
            "\n",
            "Typically, gradient clipping is applied by setting a maximum threshold value. If the gradient exceeds this threshold, it is rescaled to the threshold value, effectively \"clipping\" its magnitude. This approach helps to normalize the gradients and prevent them from overwhelming the learning process.\n",
            "\n",
            "In the context of generative models, gradient clipping can be especially useful as these models often deal with complex and high-dimensional data. By stabilizing the gradients, we can prevent sudden, large updates to the model's parameters, which could otherwise lead to unstable training dynamics and even divergence.\n",
            "\n",
            "Additionally, gradient clipping can help address the issue of exploding gradients, where gradients grow exponentially during backpropagation. Exploding gradients can cause the model to become unstable and fail to converge. By clipping the gradients, we mitigate this issue and allow for more controlled and stable updates.\n",
            "\n",
            "Overall\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Caching example 8/12\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Search\n",
            "Action Input: what is langchain\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[{'url': 'https://js.langchain.com/v0.1/docs/get_started/introduction/', 'content': 'Langchain is a framework for developing applications powered by language models. It consists of libraries, templates, and tools for connecting, reasoning, and deploying language models.'}, {'url': 'https://python.langchain.com/v0.2/docs/introduction/', 'content': \"LangChain is a Python library that simplifies the development, productionization, and deployment of applications powered by large language models (LLMs). Learn how to use LangChain's building blocks, components, and integrations to build chatbots, agents, and more.\"}, {'url': 'https://en.wikipedia.org/wiki/LangChain', 'content': 'In October 2023 LangChain introduced LangServe, a deployment tool designed to facilitate the transition from LCEL (LangChain Expression Language) prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage; API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \"todo\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database[6] to store and retrieve vector embeddings; Weaviate vector database[7] to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered popularity, with improvements from hundreds of contributors on GitHub, trending discussions on Twitter, lively activity on the project\\'s Discord server, many YouTube tutorials, and meetups in San Francisco and London. As of April 2023, it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal links[edit]'}, {'url': 'https://www.ibm.com/topics/langchain', 'content': 'Applications made with LangChain provide great utility for a variety of use cases, from straightforward question-answering and text generation tasks to more complex solutions that use an LLM as a “reasoning engine.”\\nTrain, validate, tune and deploy generative AI, foundation models and machine learning capabilities with ease and build AI applications in a fraction of the time with a fraction of the data.\\n When building a chain for an agent, inputs include:\\nDespite their heralded power and versatility, LLMs have important limitations: namely, a lack of up-to-date information, a lack of domain-specific expertise and a general difficulty with math.\\nLangChain tools\\xa0(link resides outside ibm.com) are a set of functions that empower LangChain agents to interact with real-world information in order to expand or improve the services it can provide. Launched by Harrison Chase in October 2022, LangChain enjoyed a meteoric rise to prominence: as of June 2023, it was the single fastest-growing open source project on Github.1 Coinciding with the momentous launch of OpenAI’s ChatGPT the following month, LangChain has played a significant role in making generative AI more accessible to enthusiasts in the wake of its widespread popularity.\\n Reimagine how you work with\\xa0AI: our diverse, global team of more than 20,000 AI\\xa0experts can help you quickly and confidently\\xa0design and scale AI and automation across your\\xa0business, working across our own IBM\\xa0watsonx\\xa0technology\\xa0and an open ecosystem of partners to deliver any\\xa0AI model, on any cloud, guided by ethics and trust.\\n While it’s the GPT model that interprets the user’s input and composes a natural language response, it’s the application that (among other things) provides an interface for the user to type and read and a UX design that governs the chatbot experience.'}, {'url': 'https://www.techtarget.com/searchEnterpriseAI/definition/LangChain', 'content': \"Everything you need to know\\nWhat are the features of LangChain?\\nLangChain is made up of the following modules that ensure the multiple components needed to make an effective NLP app can run smoothly:\\nWhat are the integrations of LangChain?\\nLangChain typically builds applications using integrations with LLM providers and external sources where data can be found and stored. What is synthetic data?\\nExamples and use cases for LangChain\\nThe LLM-based applications LangChain is capable of building can be applied to multiple advanced use cases within various industries and vertical markets, such as the following:\\nReaping the benefits of NLP is a key of why LangChain is important. As the airline giant moves more of its data workloads to the cloud, tools from Intel's Granulate are making platforms such as ...\\nThe vendor's new platform, now in beta testing, combines its existing lakehouse with AI to better enable users to manage and ...\\n The following steps are required to use this:\\nIn this scenario, the language model would be expected to take the two input variables -- the adjective and the content -- and produce a fascinating fact about zebras as its output.\\n The goal of LangChain is to link powerful LLMs, such as OpenAI's GPT-3.5 and GPT-4, to an array of external data sources to create and reap the benefits of natural language processing (NLP) applications.\\n\"}]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mAI: LangChain is a framework and Python library that simplifies the development, productionization, and deployment of applications powered by large language models (LLMs). It provides tools, libraries, and templates for connecting, reasoning, and deploying language models. LangChain includes modules that ensure the multiple components needed to make an effective NLP app can run smoothly. It integrates with LLM providers and external data sources, enabling the creation of advanced applications in various industries.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Caching example 9/12\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: A Recurrent Neural Network (RNN) is a type of neural network architecture commonly used for processing sequential data. Unlike traditional feedforward neural networks, RNNs have feedback connections, allowing them to exhibit temporal dynamic behavior. This makes RNNs particularly useful for tasks involving sequential data such as time series prediction, natural language processing, and speech recognition.\n",
            "\n",
            "The architecture of an RNN can be described as a chain of repeating modules, where each module is a neural network layer. The key component of an RNN is its memory or hidden state, which allows the network to remember previous inputs and use that information while processing new inputs. This is achieved by feeding the current input and the previous hidden state into the network, which then outputs a new hidden state and a prediction or output value.\n",
            "\n",
            "Mathematically, the RNN architecture can be described as follows:\n",
            "- The input at time step t is denoted as x(t).\n",
            "- The hidden state at time step t is denoted as h(t).\n",
            "- The output at time step t is denoted as y(t).\n",
            "\n",
            "The hidden state and output at time step t are calculated using the following equations:\n",
            "- h\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Caching example 10/12\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: When it comes to training generative models with limited datasets, there are several strategies that can help improve the effectiveness of the training process:\n",
            "\n",
            "- **Data Augmentation**: One common approach is to use data augmentation techniques to artificially increase the size of the dataset. This involves applying transformations or perturbations to the existing data points to create new, slightly modified versions. For example, in image data, this could include rotating, cropping, or flipping the images. In text data, augmentation techniques could involve synonym replacement, word shuffling, or paraphrasing sentences. Data augmentation helps expose the model to a larger variety of inputs, reducing overfitting and improving generalization.\n",
            "\n",
            "- **Transfer Learning**: Transfer learning involves leveraging pre-trained models that have been trained on large and diverse datasets. By using a pre-trained model as a starting point, you can take advantage of the knowledge it has already acquired and fine-tune it on your limited dataset. This approach can help speed up training and improve performance, especially when your dataset is small. Fine-tuning a pre-trained model typically involves freezing some of the earlier layers and retraining only the later layers on your specific task.\n",
            "\n",
            "- **Domain Adaptation**: Domain\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Caching example 11/12\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Curriculum learning is a training strategy where the model is exposed to training examples in a specific, ordered manner, starting with simple examples and gradually increasing the complexity. This approach is inspired by the way humans learn, where we first grasp basic concepts before moving on to more complex ones.\n",
            "\n",
            "In the context of generative models, curriculum learning can be applied by initially training the model on simpler data or tasks, and then progressively increasing the complexity of the data or the generation task. For example, when training a generative model for image synthesis, you could start with low-resolution images or simple shapes, and gradually increase the resolution or introduce more complex objects.\n",
            "\n",
            "Curriculum learning offers several advantages:\n",
            "- **Improved Convergence and Stability**: By starting with simpler examples, the model can learn basic patterns and distributions before tackling more complex ones. This helps the model to converge faster and stabilizes the training process, reducing the chances of getting stuck in poor local optima.\n",
            "- **Better Generalization**: Curriculum learning can lead to improved generalization performance, as the model learns a hierarchy of concepts and builds upon previously learned knowledge. This helps the model to better capture the underlying data distribution and generate more diverse and realistic outputs.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Caching example 12/12\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
            "AI: Learning rate scheduling is a technique used in the training of generative models, and machine learning models in general, to adjust the learning rate during the training process. The learning rate is a hyperparameter that determines the step size at which the model updates its parameters based on the gradient of the loss function.\n",
            "\n",
            "Learning rate scheduling involves dynamically changing the learning rate as the training progresses. This is done to improve the optimization process and find a better balance between exploration and exploitation. At the beginning of training, a higher learning rate is typically used to allow the model to explore the parameter space and make larger updates. As training progresses, the learning rate is gradually decreased to allow for more precise updates and to fine-tune the model's parameters.\n",
            "\n",
            "The role of learning rate scheduling in optimizing the training process of generative models is significant. It helps the model converge to a better local or global optimum by adapting the learning rate to the current state of the optimization process. A well-scheduled learning rate can speed up training, improve the model's performance, and prevent issues such as slow convergence or oscillation around the optimal solution.\n",
            "\n",
            "Different learning rate scheduling strategies can be employed, such as step-based scheduling, exponential decay\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch the interface\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "UZAkbpNDUH_w",
        "outputId": "7890d98e-5ceb-4401-890d-275daec236db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://e0822cb84b3d4c8410.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e0822cb84b3d4c8410.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}